{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMs5+9jNES/bNC7Y+KU++74"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0IL2CBiwQVUV"},"outputs":[],"source":["import pkg_resources\n","import pip\n","installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n","required = { 'pandas','numpy', 'matplotlib', 'seaborn','toad','pickle','sklearn'}\n","missing = required - installedPackages\n","if missing:\n","    !pip install pandas\n","    !pip install numpy\n","    !pip install matplotlib\n","    !pip install seaborn\n","    !pip install toad\n","    !pip install pickle\n","    !pip install sklearn"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import roc_auc_score,roc_curve,auc,precision_recall_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","import numpy as np\n","import glob\n","import math\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import toad\n","import pickle"],"metadata":{"id":"hWz1h3OCQ32A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DATA PREPROCESSING\n","\n","def data_split(df, start, end, date_col):\n","    data = df[(df[date_col] >= start) & (df[date_col] < end)]\n","    data = data.reset_index(drop=True)\n","    return data\n","\n","\n","def target_info(df_target_column):\n","\n","    proportion_true=str(round(sum(df_target_column == True) / len(df_target_column), 2) * 100)\n","\n","    proportion_false=str(round(sum(df_target_column == False) / len(df_target_column), 3) * 100)\n","\n","    print('There are total {} records in our data.'.format(len(df_target_column)))\n","    print('Bad Credit Score:')\n","    print('Count: {}'.format(sum(df_target_column == True)))\n","    print('Proportion (Bad Credit Score): {}'.format(proportion_true + '%'))\n","    print('Good Credit Score:')\n","    print('Count: {}'.format(sum(df_target_column == False)))\n","    print('Proportion (Good Credit Score): {}'.format(proportion_false + '%'))\n","    plt.figure(figsize=(5, 5))\n","    sns.barplot(x=df_target_column.value_counts().index, y=df_target_column.value_counts())\n","    plt.title('Good Credit Score vs Bad Credit Score')\n","    plt.ylabel('Count')\n","    return proportion_true"],"metadata":{"id":"Uciv5M6xQ-PS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/UCI_Credit_Card.csv')\n","data"],"metadata":{"id":"O3Lsx3j4RZhs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"hQccFDL0yB62"}},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"L20CMacMxOWT"}},{"cell_type":"code","source":["data.shape"],"metadata":{"id":"tBAxVsa0RoF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"6U8SdCVGRvLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['label']=data['default.payment.next.month']\n","data=data.drop(columns=['default.payment.next.month'])"],"metadata":{"id":"WK8UTcmARxKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_info(data['label'])"],"metadata":{"id":"14Jv-a_LR2EH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exclude_list = ['ID','label']\n","exclude_list"],"metadata":{"id":"EnKf2BEFR75j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.ID.describe()"],"metadata":{"id":"5b-u71qsSC70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = data_split(data,start = 0, end=22500,date_col='ID')\n","test = data_split(data,start = 22500, end=30000,date_col='ID')"],"metadata":{"id":"f8Jy02W-ST5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#FEATURE SELECTION\n","train_selected, drop_lst= toad.selection.select(frame = train,\n","                                                target=train['label'],\n","                                                empty = 0.7,\n","                                                iv = 0.02, corr = 1,\n","                                                return_drop=True,\n","                                                exclude=exclude_list)\n","print(\"keep:\",train_selected.shape[1],\n","      \"drop empty:\",len(drop_lst['empty']),\n","      \"drop iv:\",len(drop_lst['iv']),\n","      \"drop corr:\",len(drop_lst['corr']))"],"metadata":{"id":"GwK357mnSYNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drop_lst"],"metadata":{"id":"QpFGfTgSP_RI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def output_iv_importance(train_selected,label_col):\n","    feat_import_iv = toad.quality(train_selected,label_col,iv_only=True)\n","    feat_import_iv=feat_import_iv['iv']\n","    feat_import_iv = feat_import_iv.reset_index()\n","    feat_import_iv.columns = ['name','iv']\n","    return feat_import_iv\n","df_iv=output_iv_importance(train_selected,'label')"],"metadata":{"id":"XVzdhQwdQCNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_iv.shape"],"metadata":{"id":"85l_-D4gQHFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_iv.head(30)"],"metadata":{"id":"-aBR6oaqQOi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Feature Binning\n","#Feature binning is to transform a continuous or numerical variable into a categorical feature.\n","\n","#It simplifies the logistic regression model and reduces the risk of model overfitting\n","#Logistic regression is a generalized linear model, and its expressive ability is limited; Feature binning can introduce nonlinearity into the model, which can improve the expressive ability of the model and help better model fitting\n","#The discretized features are very robust to abnormal data: for example, a feature is 1 if age > 30, and 0 otherwise. If the features are not discretized, an abnormal data point \"300 years old\" will impact the model fitting\n","#It can treat null data as an individual class\n","\n","train_selected.label.value_counts()\n"],"metadata":{"id":"FewvOeQvQRl4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_selected.shape"],"metadata":{"id":"KxijqvQXQnaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start = time.time()\n","combiner = toad.transform.Combiner()\n","# use the filtered features for training\n","# Use the stable chi-square binning,\n","# specifying that each bin has at least 5% data to ensure stability\n","# empty values will be automatically assigned to the best bin\n","combiner.fit(X=train_selected,\n","             y=train_selected['label'],\n","             method='chi',\n","             min_samples = 0.05,\n","             exclude=exclude_list)\n","end = time.time()\n","print((end-start)/60)"],"metadata":{"id":"6MEY2-jNRIhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combiner"],"metadata":{"id":"500V1LFpTPSD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save 1: pickle combiner\n","filename = 'CreditScore_save1_combiner.pkl'\n","pickle.dump(combiner, open(filename, 'wb'))"],"metadata":{"id":"58lXJRwITY2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filename"],"metadata":{"id":"THT-uNyqTc_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output binning\n","bins = combiner.export()"],"metadata":{"id":"kMUn_TwbTgrU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(bins)"],"metadata":{"id":"1rZR4pHDT0aS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bins"],"metadata":{"id":"MJ76zOLOT3dL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#apply binning\n","train_selected_bin = combiner.transform(train_selected)\n","test_bin = combiner.transform(test[train_selected_bin.columns])"],"metadata":{"id":"uon3oodIT6qA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_selected_bin.head()"],"metadata":{"id":"PRERk0uIT96v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_bin.head()"],"metadata":{"id":"GFcOliFFUBcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features_list = [feat for feat in train_selected_bin.columns if feat not in exclude_list]\n","len(features_list)"],"metadata":{"id":"efO33vl6UD6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Fine tune bins\n","from toad.plot import  bin_plot,badrate_plot\n","bin_plot(train_selected_bin,x='PAY_AMT1',target='label')\n","bin_plot(test_bin,x='PAY_AMT1',target='label')"],"metadata":{"id":"zRrfWctGUIzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#setting rules\n","#rule = {'PAY_AMT1':[['0', 'nan'],['1'], ['2'], ['3']]}\n","\n","#Adjust binning\n","#c.set_rules(rule)\n","train_selected_bin.PAY_0.describe()"],"metadata":{"id":"nHW7VW7UUNam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Transform to WOE\n","#WOE ಮ್ಯಾಪಿಂಗ್‌ಗೆ ಪರಿವರ್ತಿಸಿ\n","t=toad.transform.WOETransformer()\n","#transform training set\n","train_woe = t.fit_transform(X=train_selected_bin,\n","                            y=train_selected_bin['label'],\n","                            exclude=exclude_list)\n","#transform testing set\n","test_woe = t.transform(test_bin)"],"metadata":{"id":"w56StCaEUSz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_woe.head()"],"metadata":{"id":"SkgJfuPzUpx6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_data_woe = pd.concat([train_woe,test_woe])\n","#save 2: pickle woe_transform\n","filename = 'CreditScore_save2_woe_transform.pkl'\n","pickle.dump(t, open(filename, 'wb'))\n","features_use = [feat for feat in final_data_woe.columns if feat not in exclude_list]\n","len(features_use)"],"metadata":{"id":"qCFnoJVuUtyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculate PSI\n","#PSI (Population Stability Index) reflects the stability of the distribution. We often use it to screen features and evaluate model stability. The industry level is to drop features with a PSI greater than 0.2\n","#get the feature name\n","features_list = [feat for feat in train_woe.columns if feat not in exclude_list]\n","#calculate PSI using toad\n","psi_df = toad.metrics.PSI(train_woe[features_list], test_woe[features_list]).sort_values(0)\n","#put into a dataframe\n","psi_df = psi_df.reset_index()\n","psi_df = psi_df.rename(columns = {'index' : 'feature',0:'psi'})\n","psi_df"],"metadata":{"id":"VW4mUkxwUuLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# features less than 0.25\n","psi025 = list(psi_df[psi_df.psi<0.25].feature)\n","# features geater than 0.25\n","psi_remove = list(psi_df[psi_df.psi>=0.25].feature)\n","psi_remove"],"metadata":{"id":"tmbYFRVlUohc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# keep exclude list\n","for i in exclude_list:\n","    if i in psi025:\n","        pass\n","    else:\n","       psi025.append(i)\n","# remove features that are geater than 0.25\n","train_selected_woe_psi = train_woe[psi025]\n","off_woe_psi = test_woe[psi025]\n","# output our final data table\n","final_data_woe = pd.concat([train_selected_woe_psi,off_woe_psi])\n","print(final_data_woe.shape)\n","(30000, 23)\n","#save 3: final data table with transformed woe\n","final_data_woe.to_csv('CreditScore_save3_final_data_woe.csv')"],"metadata":{"id":"IU07UJVlVKG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Output IV\n","features_use = [feat for feat in final_data_woe.columns if feat not in exclude_list]\n","len(features_use)\n","21\n","df_iv=output_iv_importance(final_data_woe[features_use+['label']],'label')\n","df_iv"],"metadata":{"id":"ukhFbIZzVPbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save 4: information value after woe transformation\n","df_iv.to_csv('CreditScore_save4_IV.csv')"],"metadata":{"id":"9gkr4c4BVXaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model Tuning\n","def check_train_test_auc(x_train,y_train,x_test,y_test):\n","    # ಲಾಜಿಸ್ಟಿಕ್ ರಿಗ್ರೆಶನ್ನೊಂದಿಗೆ ಮಾಡೆಲಿಂಗ್\n","    from sklearn.linear_model import LogisticRegression\n","    lr = LogisticRegression(random_state=42,C= 0.1, penalty='l2', solver='newton-cg')\n","\n","\n","    lr = LogisticRegression(class_weight='balanced')\n","    lr.fit(x_train, y_train)\n","\n","    # ಪ್ರತಿ ತಿಂಗಳಿಗೊಮ್ಮೆ ಮುನ್ಸೂಚಕ ತರಬೇತಿ ಮತ್ತು OOT\n","    pred_train = lr.predict_proba(x_train)[:,1]\n","    from toad.metrics import KS, AUC\n","\n","    print('train KS',KS(pred_train, y_train))\n","    print('train AUC',AUC(pred_train, y_train))\n","\n","    pred_OOT =lr.predict_proba(x_test)[:,1]\n","    print('Test KS',KS(pred_OOT, y_test))\n","    print('Test AUC',AUC(pred_OOT, y_test))\n","\n","    from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, plot_roc_curve, classification_report\n","\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    plot_roc_curve(lr, x_test, y_test, color='blue', ax=ax)"],"metadata":{"id":"10PoueBuVdTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Logistic Regression"],"metadata":{"id":"6IRaZqk6V1SN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_evaluation_scores(label, predictions):\n","    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","    from sklearn.metrics import balanced_accuracy_score\n","    tp, fn, fp, tn = confusion_matrix(label,predictions,labels=[1,0]).reshape(-1)\n","    print('True Positive：',tp)\n","    print('True Negative：',tn)\n","    print('False Positive：',fp)\n","    print('False Negative：',fn)\n","    accuracy = (tp+tn)/(tp+fn+fp+tn)\n","    print('accuracy: ',accuracy)\n","    recall = tp/(tp+fn)\n","    print('（recall）: ',recall)\n","    precision = tp/(tp+fp)\n","    print('（precision）: ',precision)\n","    #f1 score = 2*(P*R)/(P+R)\n","    f1 = 2*precision*recall/(precision+recall)\n","    print('F1 score: ',f1)\n","\n","    print(classification_report(label, predictions))\n","\n","    print('balanced_accuracy_score: ',balanced_accuracy_score(label,predictions))\n","    return precision, recall\n","\n","def evaluate_result(df_train,df_test,features_name):\n","    from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n","    import seaborn as sns\n","    import matplotlib.pyplot as plt\n","    start = time.time()\n","    x_train = df_train[features_name]\n","    y_train = df_train['label']\n","\n","    x_test  = df_test[features_name]\n","    y_test  = df_test['label']\n","\n","    model = GradientBoostingClassifier(n_estimators=250,random_state=0)\n","    model.fit(x_train,y_train)\n","    predictions = model.predict(x_test)\n","    get_evaluation_scores(label = y_test, predictions=predictions)\n","    feat_importances = pd.Series(model.feature_importances_, index=features_name)\n","    feat_importances=pd.DataFrame(feat_importances).reset_index()\n","    feat_importances.columns=['feature_name','feature_importance']\n","    feat_importances=feat_importances.sort_values(['feature_importance'],ascending=False)\n","    import matplotlib.pyplot as plt\n","    plt.figure(figsize=(15,15))\n","\n","    sns_plot1=sns.barplot(feat_importances.feature_importance,feat_importances.feature_name,estimator=sum)\n","    plt.title(\"Features Importance\",size=18)\n","    plt.ylabel('', size = 15)\n","    plt.tick_params(labelsize=18)\n","    return feat_importances,model,x_train,y_train,x_test,y_test"],"metadata":{"id":"fbGZNFLlV1LI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train a GBDT and check the feauture importance table\n","fet_importance_GBDT_reason,model,x_train,y_train,x_test,y_test = evaluate_result(df_train=train_woe,df_test=test_woe,features_name=features_use)\n","barplot()"],"metadata":{"id":"cOnh9shnXDlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_roc_pre_recall_curve(labels, probs):\n","    from sklearn.metrics import precision_recall_curve\n","    # Get ROC curve FPR and TPR from true labels vs score values\n","    fpr, tpr, _ = roc_curve(labels, probs)\n","\n","    # Calculate ROC Area Under the Curve (AUC) from FPR and TPR data points\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Calculate precision and recall from true labels vs score values\n","    precision, recall, _ = precision_recall_curve(labels, probs)\n","\n","    plt.figure(figsize=(8, 3))\n","\n","    plt.subplot(1,2,1)\n","    lw = 2\n","    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.4f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve')\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True)\n","\n","    plt.subplot(1,2,2)\n","    plt.step(recall, precision, color='orange', where='post')\n","    # plt.fill_between(recall, precision, step='post', alpha=0.5, color='orange')\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.ylim([0.0, 1.05])\n","    plt.xlim([0.0, 1.0])\n","    plt.title('Precision Recall Curve')\n","    plt.grid(True)\n","\n","    left  = 0.125  # the left side of the subplots of the figure\n","    right = 0.9    # the right side of the subplots of the figure\n","    bottom = 0.1   # the bottom of the subplots of the figure\n","    top = 0.9      # the top of the subplots of the figure\n","    wspace = 0.5   # the amount of width reserved for blank space between subplots\n","    hspace = 0.2   # the amount of height reserved for white space between subplots\n","    plt.subplots_adjust(left, bottom, right, top, wspace, hspace)\n","    plt.show()"],"metadata":{"id":"IGctxziXXf9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = model.predict_proba(x_test)[:,1]\n","sns.set(font_scale = 1)\n","plot_roc_pre_recall_curve(y_test, probs)"],"metadata":{"id":"nQRKQFj8X15n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model Production\n","#prepare train & test data\n","x_train = train_woe[features_use]\n","y_train=train_woe['label']\n","x_test =test_woe[features_use]\n","y_test = test_woe['label']\n","#Train LR\n","#lr = LogisticRegression(random_state=42,C= 0.1, penalty='l2', solver='newton-cg')\n","lr = LogisticRegression(class_weight = 'balanced')\n","lr.fit(x_train, y_train)"],"metadata":{"id":"vAfZia0gYuWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check AUC\n","probs = lr.predict_proba(x_test)[:,1]\n","sns.set(font_scale = 1)\n","plot_roc_pre_recall_curve(y_test, probs)"],"metadata":{"id":"jhaqjAVTY8IQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Scorecard Generation\n","# scorecard tuning\n","card = toad.ScoreCard(\n","    combiner = combiner,\n","    transer = t,\n","    class_weight = 'balanced',\n","    C=0.1,\n","    base_score = 1000,\n","    base_odds = 35 ,\n","    pdo = 80,\n","    rate = 2\n",")\n","\n","card.fit(train_woe[features_use], train_woe['label'])"],"metadata":{"id":"qkrhM3HwZAPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save 5: save the model to disk\n","filename = 'CreditScore_save5_ScoreCard.pkl'\n","pickle.dump(card, open(filename, 'wb'))"],"metadata":{"id":"vQMKbZqmZFGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inference on test data\n","test['CreditScore'] = card.predict(test)\n","test['CreditScore'].describe()"],"metadata":{"id":"t3mtHjJ0ZJkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inference on whole data\n","data['CreditScore'] = card.predict(data)\n","data['CreditScore'].describe()"],"metadata":{"id":"do6VM5pQZTLB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#output the scorecard\n","final_card_score=card.export()\n","len(final_card_score)"],"metadata":{"id":"6k3GCpPRZVEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transform the scorecard into dataframe and save to csv\n","keys = list(card.export().keys())\n","score_card_df = pd.DataFrame()\n","for n in keys:\n","    temp = pd.DataFrame.from_dict(final_card_score[n], orient='index')\n","    temp = temp.reset_index()\n","    temp.columns= ['binning','score']\n","    temp['variable'] = n\n","    temp = temp[['variable','binning','score']]\n","    score_card_df=score_card_df.append(temp)\n","score_card_df.head(30)"],"metadata":{"id":"U70a22N0Zcjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save 6: save the scorcard\n","score_card_df.to_csv('CreditScore_save6_score_card_df.csv',index=False)"],"metadata":{"id":"SDd26QCWZjoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Distribution Analysis\n","plt.figure(figsize=(12,10))\n","import random\n","import numpy\n","from matplotlib import pyplot as plt\n","\n","w = 40\n","n = math.ceil((data['CreditScore'].max() - data['CreditScore'].min())/w)\n","#bins = numpy.linspace(-10, 10, 100)\n","\n","plt.hist(data[data.label==1].CreditScore, alpha=0.5, label='Black',bins = n)\n","plt.hist(data[data.label==0].CreditScore, alpha=0.5, label='White',bins = n)\n","plt.legend(loc='upper left')\n","plt.title('Credit Score Distribution: Test Set',size=15)\n","plt.show()"],"metadata":{"id":"sRJGQRzZZnB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n","import random\n","import numpy\n","from matplotlib import pyplot as plt\n","\n","w = 40\n","n = math.ceil((test['CreditScore'].max() - test['CreditScore'].min())/w)\n","#bins = numpy.linspace(-10, 10, 100)\n","\n","plt.hist(test[test.label==1].CreditScore, alpha=0.5, label='Black',bins = n)\n","plt.hist(test[test.label==0].CreditScore, alpha=0.5, label='White',bins = n)\n","plt.legend(loc='upper left')\n","plt.title('Credit Score Distribution: Whole Dataset',size=15)\n","plt.show()"],"metadata":{"id":"s9-n-nzLZruj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Threshold Tuning\n","def get_credit_level(\n","    test,\n","    target_score ='order_score',\n","    out_col = 'order_level',\n","    left_bound = -100,\n","    level_0 = 100,\n","    level_1 = 200,\n","    level_2 = 250,\n","    level_3 = 300,\n","    level_4 = 350,\n","    level_5 = 400,\n","    level_6 = 450,\n","    level_7 = 500,\n","    level_8 = 800):\n","    level = []\n","    for i in range(len(test)):\n","        if (test[target_score][i]>left_bound) & (test[target_score][i]<=level_0):\n","            level.append(0)\n","        elif  (test[target_score][i]>level_0) & (test[target_score][i]<=level_1):\n","            level.append(1)\n","        elif  (test[target_score][i]>level_1) & (test[target_score][i]<=level_2):\n","            level.append(2)\n","        elif  (test[target_score][i]>level_2) & (test[target_score][i]<=level_3):\n","            level.append(3)\n","        elif  (test[target_score][i]>level_3) & (test[target_score][i]<=level_4):\n","            level.append(4)\n","        elif  (test[target_score][i]>level_4) & (test[target_score][i]<=level_5):\n","            level.append(5)\n","        elif  (test[target_score][i]>level_5) & (test[target_score][i]<=level_6):\n","            level.append(6)\n","        elif  (test[target_score][i]>level_6) & (test[target_score][i]<=level_7):\n","            level.append(7)\n","        elif  (test[target_score][i]>level_7 )& (test[target_score][i]<=level_8):\n","            level.append(8)\n","\n","    test[out_col] = level\n","    return test\n","\n","def plot_bts_level_loss(test, target_col):\n","    bts_level_df = test[target_col].value_counts()\n","    bts_level_df=pd.DataFrame(bts_level_df)\n","    df_label_level= test[test.label==1].groupby(target_col)['label'].count()/ test.groupby(target_col)['label'].count()\n","    df_label_level = pd.DataFrame(df_label_level)\n","    bts_level_df.sort_index().plot.bar(title='')\n","    df_label_level.plot()"],"metadata":{"id":"dviXmTYcZwc8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.CreditScore.describe()"],"metadata":{"id":"pz198tckZ31Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Threshold Tuning & Trade-off between loss & Coverage\n","test = get_credit_level(test,\n","                       target_score ='CreditScore',\n","                       out_col = 'CreditScore_level',\n","                      left_bound = -1000,\n","    level_0 = 250,\n","    level_1 = 300,\n","    level_2 = 400,\n","    level_3 = 500,\n","    level_4 = 580,\n","    level_5 = 630,\n","    level_6 = 690,\n","    level_7 = 730,\n","    level_8 = 1000\n","                )\n","plot_bts_level_loss(test,target_col='CreditScore_level')"],"metadata":{"id":"VfZ3tLrpZ7mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum(test[test.label==1].CreditScore_level==7)"],"metadata":{"id":"QIJTZxlKaFbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_loss_coverage(test,target_level):\n","\n","    #level 8 Loss\n","    L8_loss=test[test[target_level]>=8 ].label.value_counts()/len(test[test[target_level]>=8 ])\n","    #level 8 Coverage\n","    L8_coverage=test[test[target_level]>=8].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 8: Loss is \",L8_loss[1], \"; Coverage is \",L8_coverage)\n","\n","    #level 7-level 8 Loss\n","    L7_loss=test[test[target_level]>=7 ].label.value_counts()/len(test[test[target_level]>=7 ])\n","    #level 7-level 8 Coverage\n","    L7_coverage=test[test[target_level]>=7].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 7-Level 8: Loss is \",L7_loss[1], \"; Coverage is \",L7_coverage)\n","\n","    #level 6-level 8 Loss\n","    L6_loss=test[test[target_level]>=6 ].label.value_counts()/len(test[test[target_level]>=6 ])\n","    #level 6-level 8 Coverage\n","    L6_coverage=test[test[target_level]>=6].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 6-Level 8: Loss is \",L6_loss[1], \"; Coverage is \",L6_coverage)\n","\n","     #level 5-Leve 8 Loss (percentage of default people)\n","    L5_loss = test[test[target_level]>=5 ].label.value_counts()/len(test[test[target_level]>=5 ])\n","    #level 5- level 8 Coverage (percentage of good people)\n","    L5_coverage=test[test[target_level]>=5 ].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 5-Level 8: Loss is \",L5_loss[1], \"; Coverage is \",L5_coverage)\n","\n","    #level 4-level 8 Loss\n","    L4_loss=test[test[target_level]>=4 ].label.value_counts()/len(test[test[target_level]>=4 ])\n","    #level 4-level 8 Coverage\n","    L4_coverage=test[test[target_level]>=4].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 4-Level 8: Loss is \",L4_loss[1], \"; Coverage is \",L4_coverage)\n","\n","\n","    #level 3-level 8 Loss\n","    L3_loss=test[test[target_level]>=3].label.value_counts()/len(test[test[target_level]>=3 ])\n","    #level 3-level 8 Coverage\n","    L3_coverage=test[test[target_level]>=3].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 3-Level 8: Loss is \",L3_loss[1], \"; Coverage is \",L3_coverage)\n","\n","    #level 2-level 8 Loss\n","    L2_loss=test[test[target_level]>=2].label.value_counts()/len(test[test[target_level]>=2 ])\n","    #level 2-level 8 Coverage\n","    L2_coverage=test[test[target_level]>=2].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 2-Level 8: Loss is \",L2_loss[1], \"; Coverage is \",L2_coverage)\n","\n","    #level 1-level 8 Loss\n","    L1_loss=test[test[target_level]>=1].label.value_counts()/len(test[test[target_level]>=1 ])\n","    #level 1-level 8 Coverage\n","    L1_coverage=test[test[target_level]>=1].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 1-Level 8: Loss is \",L1_loss[1], \"; Coverage is \",L1_coverage)\n","\n","    #level 0-level 8 Loss\n","    L0_loss=test[test[target_level]>=0].label.value_counts()/len(test[test[target_level]>=0 ])\n","    #level 0-level 8 Coverage\n","    L0_coverage=test[test[target_level]>=0].label.value_counts()[0]/test[test.label==0].shape[0]\n","    print(\"Level 0-Level 8: Loss is \",L0_loss[1], \"; Coverage is \",L0_coverage)\n","get_loss_coverage(test,target_level='CreditScore_level')"],"metadata":{"id":"fe7VsbUlaJeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.to_csv('OrderScore_save7_whole_data.csv',index=False)\n","\n","test.loc[0,:]"],"metadata":{"id":"d8zwXCWcaPFX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["card.predict(test)[0]"],"metadata":{"id":"ZneTS9FLaT98"},"execution_count":null,"outputs":[]}]}